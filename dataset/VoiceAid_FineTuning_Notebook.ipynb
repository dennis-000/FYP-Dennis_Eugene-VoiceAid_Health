{
    "nbformat": 4,
    "nbformat_minor": 5,
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        },
        "colab": {
            "provenance": [],
            "gpuType": "A100"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "id": "title-cell",
            "metadata": {},
            "source": [
                "# ðŸš€ VoiceAid Health â€” Akan ASR: Fine-Tuning\n",
                "\n",
                "This notebook trains (fine-tunes) your custom model (`dennis-9/whisper-small_Akan_non_standardspeech`) on your **8,084 speech-impaired Akan audio dataset** to improve accuracy.\n",
                "\n",
                "**Before running:**\n",
                "- Enable GPU: **Runtime â†’ Change runtime type â†’ T4 GPU** (or A100/L4 if you have Colab Pro)\n",
                "- Ensure your dataset and audio are in Google Drive."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-1-install",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 1: Install Dependencies\n",
                "!pip install -q transformers datasets evaluate jiwer accelerate librosa soundfile torchaudio huggingface_hub\n",
                "print('âœ… Dependencies installed!')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-2-login",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 2: Login to Hugging Face\n",
                "# You need to log in to upload the newly trained model to your account.\n",
                "# Get your Write token from: https://huggingface.co/settings/tokens\n",
                "from huggingface_hub import notebook_login\n",
                "notebook_login()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-3-mount",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 3: Mount Google Drive & Set Paths\n",
                "from google.colab import drive\n",
                "import os\n",
                "import pandas as pd\n",
                "\n",
                "drive.mount('/content/drive')\n",
                "print('âœ… Google Drive mounted!')\n",
                "\n",
                "# â”€â”€ PATHS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "AUDIO_DIR     = '/content/drive/MyDrive/VoiceAid_Dataset/audio/audios' # based on your previous evaluation\n",
                "DATASET_EXCEL = '/content/drive/MyDrive/VoiceAid_Dataset/akan_dataset.csv'\n",
                "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "\n",
                "df = pd.read_csv(DATASET_EXCEL)\n",
                "print(f'âœ… Dataset loaded: {len(df)} rows')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-4-prepare-dataset",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 4: Prepare Hugging Face Dataset\n",
                "from datasets import Dataset, Audio\n",
                "\n",
                "print(\"ðŸ” Verifying audio files...\")\n",
                "df['audio_path'] = df['file_name'].apply(lambda x: os.path.join(AUDIO_DIR, str(x)))\n",
                "\n",
                "# Only keep rows where the audio file actually exists\n",
                "df_filtered = df[df['audio_path'].apply(os.path.exists)].copy()\n",
                "print(f\"Found {len(df_filtered)} valid audio files out of {len(df)}\")\n",
                "\n",
                "df_filtered = df_filtered[['audio_path', 'text']]\n",
                "df_filtered = df_filtered.rename(columns={'audio_path': 'audio'})\n",
                "\n",
                "# Convert to Hugging Face Dataset\n",
                "dataset = Dataset.from_pandas(df_filtered, preserve_index=False)\n",
                "\n",
                "# Cast the audio column to the Audio feature type at 16kHz\n",
                "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
                "\n",
                "# Split into Train (90%) and Test/Validation (10%)\n",
                "dataset = dataset.train_test_split(test_size=0.1, seed=42)\n",
                "print(\"\\nâœ… Dataset prepared:\")\n",
                "print(dataset)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-5-processor",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 5: Load Processor & Tokenizer\n",
                "from transformers import WhisperProcessor\n",
                "\n",
                "MODEL_ID = \"dennis-9/whisper-small_Akan_non_standardspeech\"\n",
                "print(f\"ðŸ“¥ Loading processor from {MODEL_ID}...\")\n",
                "processor = WhisperProcessor.from_pretrained(MODEL_ID)\n",
                "print(\"âœ… Processor loaded!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-6-preprocess",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 6: Preprocess Audio & Text (Feature Extraction)\n",
                "print(\"â³ Processing audio into spectrograms (this will take a while)...\")\n",
                "\n",
                "def prepare_dataset(batch):\n",
                "    # Load and resample audio data\n",
                "    audio = batch[\"audio\"]\n",
                "\n",
                "    # Compute log-Mel input features from input audio array\n",
                "    batch[\"input_features\"] = processor.feature_extractor(\n",
                "        audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]\n",
                "    ).input_features[0]\n",
                "\n",
                "    # Encode target text to label ids\n",
                "    batch[\"labels\"] = processor.tokenizer(batch[\"text\"]).input_ids\n",
                "    return batch\n",
                "\n",
                "# Map the function to the dataset (removes original columns to save RAM)\n",
                "tokenized_dataset = dataset.map(\n",
                "    prepare_dataset,\n",
                "    remove_columns=dataset.column_names[\"train\"],\n",
                "    num_proc=4 # Uses multiple CPU cores for speed\n",
                ")\n",
                "print(\"âœ… Preprocessing complete!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-7-collator",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 7: Define Data Collator for Padding\n",
                "import torch\n",
                "from dataclasses import dataclass\n",
                "from typing import Any, Dict, List, Union\n",
                "\n",
                "@dataclass\n",
                "class DataCollatorSpeechSeq2SeqWithPadding:\n",
                "    processor: Any\n",
                "\n",
                "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
                "        # Split inputs and labels since they have to be of different lengths and need different padding methods\n",
                "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
                "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
                "\n",
                "        # Get the tokenized label sequences\n",
                "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
                "        # Pad the labels to max length\n",
                "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
                "\n",
                "        # Replace padding with -100 to ignore loss correctly\n",
                "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
                "        \n",
                "        # If boss token is appended in previous tokenization step,\n",
                "        # cut boss token here as it's append later anyways\n",
                "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
                "            labels = labels[:, 1:]\n",
                "\n",
                "        batch[\"labels\"] = labels\n",
                "        return batch\n",
                "\n",
                "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n",
                "print(\"âœ… Collator ready!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-8-metrics",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 8: Define Metrics (WER)\n",
                "import evaluate\n",
                "\n",
                "metric = evaluate.load(\"wer\")\n",
                "\n",
                "def compute_metrics(pred):\n",
                "    pred_ids = pred.predictions\n",
                "    label_ids = pred.label_ids\n",
                "\n",
                "    # Replace -100 with the pad_token_id\n",
                "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
                "\n",
                "    # We do not want to group tokens when computing the metrics\n",
                "    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
                "    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
                "\n",
                "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
                "    return {\"wer\": wer}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-9-model",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 9: Load the Base Model for Training\n",
                "from transformers import WhisperForConditionalGeneration\n",
                "\n",
                "print(f\"ðŸ“¥ Loading model for training: {MODEL_ID}...\")\n",
                "model = WhisperForConditionalGeneration.from_pretrained(MODEL_ID)\n",
                "\n",
                "model.config.forced_decoder_ids = None\n",
                "model.config.suppress_tokens = []\n",
                "print(\"âœ… Model loaded and ready to train!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-10-train",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 10: Set Training Arguments & Start Training!\n",
                "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
                "\n",
                "# We will append \"_v2\" to your repository name to distinguish it.\n",
                "YOUR_HF_USERNAME = \"dennis-9\" # Make sure this matches your HF account\n",
                "REPO_NAME = f\"{MODEL_ID.split('/')[1]}_v2\"\n",
                "\n",
                "training_args = Seq2SeqTrainingArguments(\n",
                "    output_dir=REPO_NAME,     # The directory where checkpoints are saved\n",
                "    per_device_train_batch_size=16,\n",
                "    gradient_accumulation_steps=1,  # Increase by 2x for every 2x decrease in batch size\n",
                "    learning_rate=1e-5,\n",
                "    warmup_steps=500,\n",
                "    max_steps=4000,           # Number of training steps (adjust based on how long it takes)\n",
                "    gradient_checkpointing=True,\n",
                "    fp16=True,\n",
                "    eval_strategy=\"steps\",\n",
                "    per_device_eval_batch_size=8,\n",
                "    predict_with_generate=True,\n",
                "    generation_max_length=225,\n",
                "    save_steps=1000,\n",
                "    eval_steps=1000,\n",
                "    logging_steps=25,\n",
                "    report_to=[\"tensorboard\"],\n",
                "    load_best_model_at_end=True,\n",
                "    metric_for_best_model=\"wer\",\n",
                "    greater_is_better=False,\n",
                "    push_to_hub=True,\n",
                ")\n",
                "\n",
                "trainer = Seq2SeqTrainer(\n",
                "    args=training_args,\n",
                "    model=model,\n",
                "    train_dataset=tokenized_dataset[\"train\"],\n",
                "    eval_dataset=tokenized_dataset[\"test\"],\n",
                "    data_collator=data_collator,\n",
                "    compute_metrics=compute_metrics,\n",
                "    processing_class=processor,\n",
                ")\n",
                "\n",
                "print(\"ðŸš€ Starting Training... Grab a coffee, this will take hours depending on GPU!\")\n",
                "trainer.train()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-11-push",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 11: Push Final Model to Hugging Face\n",
                "print(\"ðŸ“¤ Pushing model to Hugging Face Hub...\")\n",
                "trainer.push_to_hub(commit_message=\"Training complete on Colab\")\n",
                "print(f\"âœ… Successfully uploaded to: https://huggingface.co/{YOUR_HF_USERNAME}/{REPO_NAME}\")"
            ]
        }
    ]
}