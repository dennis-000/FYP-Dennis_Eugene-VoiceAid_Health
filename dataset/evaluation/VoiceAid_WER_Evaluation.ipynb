{
    "nbformat": 4,
    "nbformat_minor": 5,
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        },
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "id": "title-cell",
            "metadata": {},
            "source": [
                "# ğŸ™ï¸ VoiceAid Health â€” Akan ASR: WER Evaluation\n",
                "\n",
                "Evaluates `dennis-9/whisper-small_Akan_non_standardspeech` using **Word Error Rate (WER)**.\n",
                "\n",
                "**Before running:**\n",
                "- Enable GPU: **Runtime â†’ Change runtime type â†’ T4 GPU**\n",
                "- Ensure these exist on your Google Drive:\n",
                "  - `MyDrive/VoiceAid_Dataset/akan_dataset.xlsx`\n",
                "  - `MyDrive/VoiceAid_Dataset/audio/` (folder with all .wav files)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-1-install",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 1: Install Dependencies\n",
                "!pip install -q transformers torch torchaudio jiwer openpyxl accelerate pandas\n",
                "print('âœ… Dependencies installed!')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-2-mount",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 2: Mount Google Drive & Set Paths\n",
                "from google.colab import drive\n",
                "import os\n",
                "\n",
                "drive.mount('/content/drive')\n",
                "print('âœ… Google Drive mounted!')\n",
                "\n",
                "# â”€â”€ PATHS (update if your folder names differ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "AUDIO_DIR     = '/content/drive/MyDrive/VoiceAid_Dataset/audio/'\n",
                "DATASET_EXCEL = '/content/drive/MyDrive/VoiceAid_Dataset/akan_dataset.xlsx'\n",
                "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "\n",
                "wav_files = [f for f in os.listdir(AUDIO_DIR) if f.endswith('.wav')]\n",
                "print(f'ğŸµ Found {len(wav_files)} .wav files in {AUDIO_DIR}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-3-load-dataset",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 3: Load Dataset\n",
                "import pandas as pd\n",
                "\n",
                "df = pd.read_excel(DATASET_EXCEL)\n",
                "print(f'âœ… Dataset loaded: {len(df)} rows')\n",
                "print(f'   Columns: {list(df.columns)}')\n",
                "print(f'\\n   Severity breakdown:')\n",
                "print(df['Severity'].value_counts())\n",
                "print(f'\\n   Sample rows:')\n",
                "df[['file_name', 'text', 'Severity', 'condition']].head(5)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-4-load-model",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 4: Load Your Custom Akan Model\n",
                "import torch\n",
                "from transformers import pipeline\n",
                "\n",
                "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
                "print(f'ğŸ–¥ï¸  Device: {device}')\n",
                "\n",
                "MODEL_ID = 'dennis-9/whisper-small_Akan_non_standardspeech'\n",
                "print(f'ğŸ“¥ Loading model: {MODEL_ID}...')\n",
                "\n",
                "pipe = pipeline(\n",
                "    'automatic-speech-recognition',\n",
                "    model=MODEL_ID,\n",
                "    device=device,\n",
                "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
                ")\n",
                "print('âœ… Model loaded!')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-5-wer-eval",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 5: Run WER Evaluation\n",
                "from jiwer import wer, cer\n",
                "\n",
                "# â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "SAMPLE_SIZE     = 100   # Start small. Set to len(df) for full eval (~30-60 mins)\n",
                "SEVERITY_FILTER = None  # 'Mild', 'Moderate', 'Severe', or None for all\n",
                "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "\n",
                "if SEVERITY_FILTER:\n",
                "    eval_df = df[df['Severity'] == SEVERITY_FILTER].sample(\n",
                "        min(SAMPLE_SIZE, len(df[df['Severity'] == SEVERITY_FILTER])), random_state=42\n",
                "    )\n",
                "else:\n",
                "    eval_df = df.sample(min(SAMPLE_SIZE, len(df)), random_state=42)\n",
                "\n",
                "print(f'ğŸ§ª Evaluating {len(eval_df)} samples (Severity: {SEVERITY_FILTER or \"All\"})...')\n",
                "\n",
                "references, hypotheses, errors = [], [], []\n",
                "\n",
                "for idx, row in eval_df.iterrows():\n",
                "    audio_path = os.path.join(AUDIO_DIR, str(row['file_name']))\n",
                "    if not os.path.exists(audio_path):\n",
                "        errors.append(f'Missing: {row[\"file_name\"]}')\n",
                "        continue\n",
                "    try:\n",
                "        result = pipe(audio_path, generate_kwargs={\n",
                "            'max_new_tokens': 256,\n",
                "            'temperature': 0.0,\n",
                "            'num_beams': 5,\n",
                "        })\n",
                "        references.append(str(row['text']))\n",
                "        hypotheses.append(result['text'].strip())\n",
                "    except Exception as e:\n",
                "        errors.append(f'Error on {row[\"file_name\"]}: {e}')\n",
                "\n",
                "overall_wer = wer(references, hypotheses)\n",
                "overall_cer = cer(references, hypotheses)\n",
                "\n",
                "print(f'\\n{\"=\"*50}')\n",
                "print(f'ğŸ“Š EVALUATION RESULTS ({len(references)} samples)')\n",
                "print(f'{\"=\"*50}')\n",
                "print(f'  Word Error Rate  (WER): {overall_wer:.2%}  â† Lower is better')\n",
                "print(f'  Char Error Rate  (CER): {overall_cer:.2%}  â† Lower is better')\n",
                "print(f'  Accuracy (approx):      {(1-overall_wer):.2%}')\n",
                "print(f'  Missing/Errored:        {len(errors)}')\n",
                "print(f'{\"=\"*50}')\n",
                "\n",
                "print('\\nğŸ“ Sample Predictions:')\n",
                "for ref, hyp in list(zip(references, hypotheses))[:5]:\n",
                "    print(f'  REF: {ref}')\n",
                "    print(f'  HYP: {hyp}\\n')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-6-severity-breakdown",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 6: WER Breakdown by Severity Level\n",
                "from jiwer import wer\n",
                "\n",
                "print('ğŸ“Š WER by Severity Level')\n",
                "print('='*40)\n",
                "\n",
                "for severity in sorted(df['Severity'].dropna().unique()):\n",
                "    sev_df = df[df['Severity'] == severity].sample(\n",
                "        min(50, len(df[df['Severity'] == severity])), random_state=42\n",
                "    )\n",
                "    sev_refs, sev_hyps = [], []\n",
                "    for _, row in sev_df.iterrows():\n",
                "        audio_path = os.path.join(AUDIO_DIR, str(row['file_name']))\n",
                "        if not os.path.exists(audio_path): continue\n",
                "        try:\n",
                "            result = pipe(audio_path, generate_kwargs={'max_new_tokens': 256, 'temperature': 0.0})\n",
                "            sev_refs.append(str(row['text']))\n",
                "            sev_hyps.append(result['text'].strip())\n",
                "        except: continue\n",
                "\n",
                "    if sev_refs:\n",
                "        sev_wer = wer(sev_refs, sev_hyps)\n",
                "        bar = 'â–ˆ' * int((1 - sev_wer) * 20)\n",
                "        print(f'  {severity:12s}: WER = {sev_wer:.2%}  [{bar:<20}] ({len(sev_refs)} samples)')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-7-save-results",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 7: Save Results to Google Drive\n",
                "import json\n",
                "\n",
                "results = {\n",
                "    'model': MODEL_ID,\n",
                "    'sample_size': len(references),\n",
                "    'overall_wer': round(overall_wer, 4),\n",
                "    'overall_cer': round(overall_cer, 4),\n",
                "    'accuracy_approx': round(1 - overall_wer, 4),\n",
                "    'severity_filter': SEVERITY_FILTER or 'All',\n",
                "    'missing_or_errored': len(errors),\n",
                "}\n",
                "\n",
                "RESULTS_PATH = '/content/drive/MyDrive/VoiceAid_Dataset/wer_results.json'\n",
                "with open(RESULTS_PATH, 'w') as f:\n",
                "    json.dump(results, f, indent=2)\n",
                "\n",
                "print(f'âœ… Results saved to: {RESULTS_PATH}')\n",
                "print(json.dumps(results, indent=2))"
            ]
        }
    ]
}